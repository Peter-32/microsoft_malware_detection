{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding\n",
    "\n",
    "- I skimmed the data descriptions\n",
    "- I found no date fields\n",
    "- I found number fields that should be strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/petermyers/Desktop/Code/commons/venv/lib/python3.6/site-packages/ipykernel_launcher.py:39: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5883b8880bb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# The index is the unique key for each observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MachineIdentifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# y_name is the output variable name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from pandas import read_csv, value_counts, concat, get_dummies\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "\n",
    "# Number fields that should be strings\n",
    "converters = {'DefaultBrowsersIdentifier': str, 'AVProductStatesIdentifier': str,\n",
    "              'CountryIdentifier': str, 'CityIdentifier': str,\n",
    "              'OrganizationIdentifier': str, 'GeoNameIdentifier': str,\n",
    "              'LocaleEnglishNameIdentifier': str, 'IeVerIdentifier': str,\n",
    "              'Census_OEMNameIdentifier': str, 'Census_OEMModelIdentifier': str,\n",
    "              'Census_ProcessorManufacturerIdentifier': str,\n",
    "              'Census_ProcessorModelIdentifier': str,\n",
    "              'Census_OSInstallLanguageIdentifier': str,\n",
    "              'Census_OSUILocaleIdentifier': str,\n",
    "              'Census_FirmwareManufacturerIdentifier': str,\n",
    "              'Census_FirmwareVersionIdentifier': str, 'Wdft_RegionIdentifier': str,\n",
    "              'OsBuild': str, 'OsSuite': str,\n",
    "              'Census_InternalBatteryNumberOfCharges': str,\n",
    "              'Census_OSBuildNumber': str, 'Census_OSBuildRevision': str\n",
    "              }\n",
    "\n",
    "# Read in training dataset\n",
    "train_df = read_csv(\"/users/petermyers/data/microsoft_malware_prediction/train.csv\",\n",
    "                    # nrows=1000,\n",
    "                    converters=converters)\n",
    "\n",
    "# Read in test dataset\n",
    "test_df = read_csv(\"/users/petermyers/data/microsoft_malware_prediction/test.csv\",\n",
    "                   # nrows=1000,\n",
    "                   converters=converters)\n",
    "\n",
    "# Add the holdout field\n",
    "train_df.loc[:, 'holdout'] = 0\n",
    "test_df.loc[:, 'holdout'] = 1\n",
    "\n",
    "# Combine the two datasets\n",
    "df = concat([train_df, test_df], axis=0)\n",
    "\n",
    "# The index is the unique key for each observation\n",
    "index = df['MachineIdentifier']\n",
    "\n",
    "# y_name is the output variable name\n",
    "y_name = 'HasDetections'\n",
    "\n",
    "# Delete the test_df variable.  It's no longer needed.\n",
    "del test_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "def remove_infinity_values(df):\n",
    "    print(\"Replacing infinity values with nan\")\n",
    "    return df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "df = remove_infinity_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Missing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "def remove_columns_where_every_value_is_nan(df, train_df):\n",
    "    print(\"Dropping columns with all nan values\")\n",
    "    train_df.dropna(axis=1, how='all', inplace=True)\n",
    "    return df[train_df.columns.values]\n",
    "\n",
    "df = remove_columns_where_every_value_is_nan(df, train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "def fix_missing_values(df, train_df):\n",
    "    print(\"Fixing missing values\")\n",
    "    for column in df.columns:\n",
    "        \n",
    "        # Ignore y_name and holdout columns\n",
    "        if column in (y_name, 'holdout'):\n",
    "            continue\n",
    "            \n",
    "        # Integer columns\n",
    "        if df[column].dtype in ('int64', 'float64', 'uint8'):\n",
    "            df.loc[:, column] = df[column].fillna(train_df[column].mean())\n",
    "        \n",
    "        # Categories and dates\n",
    "        else:\n",
    "            df.loc[:, column] = 'none'\n",
    "    return df\n",
    "\n",
    "df = fix_missing_values(df, train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Category Values\n",
    "- Categories must be converted to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "def add_dummy_values(df, train_df):\n",
    "    print(\"Adding Dummy Values\")\n",
    "    for column in df.columns:\n",
    "\n",
    "        # Temporary print statement while debugging\n",
    "        print(column)\n",
    "        \n",
    "        # Ignore y_name and holdout columns\n",
    "        if column in (y_name, 'holdout'):\n",
    "            continue\n",
    "            \n",
    "        # Ignore number columns\n",
    "        if df[column].dtype in ('int64', 'float64', 'uint8'):\n",
    "            continue\n",
    "\n",
    "        # Check if an \"_Other\" value is necessary\n",
    "        has_other_value = False\n",
    "        if len(train_df[column].unique()) > 4:\n",
    "            has_other_value = True\n",
    "\n",
    "        # Find the common column values\n",
    "        if has_other_value:                \n",
    "            d = value_counts(\n",
    "                train_df[column].values, sort=True, normalize=True).to_dict()\n",
    "            common_values_dict = dict((k, v)\n",
    "                                      for k, v in d.items() if v >= 0.05)\n",
    "            del d\n",
    "            \n",
    "        # Update the DF to use _Other values\n",
    "        if has_other_value:            \n",
    "            for index, row in df.iterrows():\n",
    "                if row[column] not in common_values_dict.keys():\n",
    "                    df.at[index, column] = '_Other'\n",
    "                                    \n",
    "        # Add dummies to dataframe\n",
    "        df = concat([df.drop([column], axis=1), get_dummies(\n",
    "            df[column], prefix=column+\"_\", drop_first=False)], axis=1)\n",
    "        \n",
    "        # Drop _Other dummies column\n",
    "        if has_other_value:\n",
    "            df.drop([\"{}___Other\".format(column)], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "df = add_dummy_values(df, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/petermyers/Desktop/Code/commons/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/petermyers/Desktop/Code/commons/venv/lib/python3.6/site-packages/ipykernel_launcher.py:28: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing infinity values\n",
      "Dropping columns with all nan values\n",
      "Fixing missing values\n",
      "Adding Dummy Values\n",
      "MachineIdentifier\n",
      "Doing value counts\n",
      "Updating to _Other\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-168bee674bb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix_missing_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Adding Dummy Values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_dummy_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Subsetting data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubset_X_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset_X_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-168bee674bb4>\u001b[0m in \u001b[0;36madd_dummy_values\u001b[0;34m(df, train_df)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcommon_values_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'_Other'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final dummies calculation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# Convert to dummies and add to the dataframe and drop _Other\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Code/commons/venv/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Code/commons/venv/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_value\u001b[0;34m(self, index, col, value, takeable)\u001b[0m\n\u001b[1;32m   2580\u001b[0m             \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2581\u001b[0m             \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2582\u001b[0;31m             \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2583\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def subset_X_data(df, holdout_value):\n",
    "    return df.loc[df['holdout'] == holdout_value].drop([y_name, 'holdout'], axis=1).values\n",
    "\n",
    "\n",
    "def subset_y_data(df, holdout_value):\n",
    "    return df.loc[df['holdout'] == holdout_value][y_name].values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subsetting data\")\n",
    "train_X, test_X = subset_X_data(df, 0), subset_X_data(df, 1)\n",
    "train_y, test_y = subset_y_data(df, 0), subset_y_data(df, 1)\n",
    "lasso = Lasso()\n",
    "lasso.fit(train_X, train_y)\n",
    "print(\"\\nBest columns\\n============\")\n",
    "for column, coef in zip(df.columns[:-1], lasso.coef_):\n",
    "    if coef != 0.0:\n",
    "        print(column, '%s' % float('%.4g' % coef))\n",
    "print(\"\")\n",
    "pred = lasso.predict(np.concatenate([train_X, test_X]))\n",
    "df['index'] = index\n",
    "df['pred'] = [max(min(x, 1.0), 0.0) for x in pred]\n",
    "df['true_y'] = df[y_name]\n",
    "print(\"Subsetting final data\")\n",
    "final_df = df.loc[df['holdout'] == 1]\n",
    "final_df = final_df[['index', 'pred']]\n",
    "final_df.columns = ['MachineIdentifier', 'HasDetections']\n",
    "print(\"Saving to submission.csv\")\n",
    "final_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "commons",
   "language": "python",
   "name": "commons"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
